; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=mina32 -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=M32I %s

; As well as calling convention details, we check that r14 is
; consistently stored to fp-4.

; Check that i128 and fp128 are split

define i32 @callee_large_scalars(i128 %a, fp128 %b) nounwind {
; M32I-LABEL: callee_large_scalars:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -12
; M32I-NEXT:    st r14, [sp, 8]
; M32I-NEXT:    st r4, [sp, 4]
; M32I-NEXT:    st r5, [sp, 0]
; M32I-NEXT:    addi r14, sp, 12
; M32I-NEXT:    addi r4, r14, 4
; M32I-NEXT:    ld r5, [r4, 12]
; M32I-NEXT:    xor r3, r3, r5
; M32I-NEXT:    ld r5, [r4, 4]
; M32I-NEXT:    xor r1, r1, r5
; M32I-NEXT:    or r1, r1, r3
; M32I-NEXT:    ld r3, [r14, 4]
; M32I-NEXT:    xor r0, r0, r3
; M32I-NEXT:    ld r3, [r4, 8]
; M32I-NEXT:    xor r2, r2, r3
; M32I-NEXT:    or r0, r0, r2
; M32I-NEXT:    or r0, r0, r1
; M32I-NEXT:    cmpi.eq r0, 0
; M32I-NEXT:    movi r0, 0
; M32I-NEXT:    mti r0, 1
; M32I-NEXT:    ld r5, [sp, 0]
; M32I-NEXT:    ld r4, [sp, 4]
; M32I-NEXT:    ld r14, [sp, 8]
; M32I-NEXT:    addi sp, sp, 12
; M32I-NEXT:    ret
  %b_bitcast = bitcast fp128 %b to i128
  %1 = icmp eq i128 %a, %b_bitcast
  %2 = zext i1 %1 to i32
  ret i32 %2
}

define i32 @caller_large_scalars() nounwind {
; M32I-LABEL: caller_large_scalars:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -24
; M32I-NEXT:    st r14, [sp, 20]
; M32I-NEXT:    st r4, [sp, 16]
; M32I-NEXT:    addi r14, sp, 24
; M32I-NEXT:    movu r0, 32767
; M32I-NEXT:    st r0, [sp, 12]
; M32I-NEXT:    movi r1, 0
; M32I-NEXT:    st r1, [sp, 8]
; M32I-NEXT:    st r1, [sp, 4]
; M32I-NEXT:    st r1, [sp, 0]
; M32I-NEXT:    movu r4, %hi(callee_large_scalars)
; M32I-NEXT:    movl r4, %lo(callee_large_scalars)
; M32I-NEXT:    movi r0, 1
; M32I-NEXT:    mov r2, r1
; M32I-NEXT:    mov r3, r1
; M32I-NEXT:    rcall r4, 0
; M32I-NEXT:    ld r4, [sp, 16]
; M32I-NEXT:    ld r14, [sp, 20]
; M32I-NEXT:    addi sp, sp, 24
; M32I-NEXT:    ret
  %1 = call i32 @callee_large_scalars(i128 1, fp128 0xL00000000000000007FFF000000000000)
  ret i32 %1
}

; Must keep define on a single line due to an update_llc_test_checks.py limitation
define i32 @callee_large_scalars_exhausted_regs(i32 %a, i32 %b, i32 %c, i32 %d, i32 %e, i32 %f, i32 %g, i128 %h, i32 %i, fp128 %j) nounwind {
; Check that large scalar arguments are handled correctly when their
; address is passed on the stack rather than in memory
; M32I-LABEL: callee_large_scalars_exhausted_regs:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -8
; M32I-NEXT:    st r14, [sp, 4]
; M32I-NEXT:    st r4, [sp, 0]
; M32I-NEXT:    addi r14, sp, 8
; M32I-NEXT:    addi r0, r14, 36
; M32I-NEXT:    ld r1, [r0, 12]
; M32I-NEXT:    addi r2, r14, 16
; M32I-NEXT:    ld r3, [r2, 12]
; M32I-NEXT:    xor r1, r3, r1
; M32I-NEXT:    ld r3, [r0, 4]
; M32I-NEXT:    ld r4, [r2, 4]
; M32I-NEXT:    xor r3, r4, r3
; M32I-NEXT:    or r1, r3, r1
; M32I-NEXT:    ld r3, [r14, 36]
; M32I-NEXT:    ld r4, [r14, 16]
; M32I-NEXT:    xor r3, r4, r3
; M32I-NEXT:    ld r0, [r0, 8]
; M32I-NEXT:    ld r2, [r2, 8]
; M32I-NEXT:    xor r0, r2, r0
; M32I-NEXT:    or r0, r3, r0
; M32I-NEXT:    or r0, r0, r1
; M32I-NEXT:    cmpi.eq r0, 0
; M32I-NEXT:    movi r0, 0
; M32I-NEXT:    mti r0, 1
; M32I-NEXT:    ld r4, [sp, 0]
; M32I-NEXT:    ld r14, [sp, 4]
; M32I-NEXT:    addi sp, sp, 8
; M32I-NEXT:    ret
  %j_bitcast = bitcast fp128 %j to i128
  %1 = icmp eq i128 %h, %j_bitcast
  %2 = zext i1 %1 to i32
  ret i32 %2
}

define i32 @caller_large_scalars_exhausted_regs() nounwind {
; M32I-LABEL: caller_large_scalars_exhausted_regs:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -56
; M32I-NEXT:    st r14, [sp, 52]
; M32I-NEXT:    st r4, [sp, 48]
; M32I-NEXT:    addi r14, sp, 56
; M32I-NEXT:    movu r0, 32767
; M32I-NEXT:    st r0, [sp, 44]
; M32I-NEXT:    movi r0, 9
; M32I-NEXT:    st r0, [sp, 28]
; M32I-NEXT:    movi r0, 0
; M32I-NEXT:    st r0, [sp, 40]
; M32I-NEXT:    st r0, [sp, 36]
; M32I-NEXT:    st r0, [sp, 32]
; M32I-NEXT:    st r0, [sp, 24]
; M32I-NEXT:    st r0, [sp, 20]
; M32I-NEXT:    st r0, [sp, 16]
; M32I-NEXT:    movi r0, 8
; M32I-NEXT:    st r0, [sp, 12]
; M32I-NEXT:    movi r0, 7
; M32I-NEXT:    st r0, [sp, 8]
; M32I-NEXT:    movi r0, 6
; M32I-NEXT:    st r0, [sp, 4]
; M32I-NEXT:    movi r0, 5
; M32I-NEXT:    st r0, [sp, 0]
; M32I-NEXT:    movu r4, %hi(callee_large_scalars_exhausted_regs)
; M32I-NEXT:    movl r4, %lo(callee_large_scalars_exhausted_regs)
; M32I-NEXT:    movi r0, 1
; M32I-NEXT:    movi r1, 2
; M32I-NEXT:    movi r2, 3
; M32I-NEXT:    movi r3, 4
; M32I-NEXT:    rcall r4, 0
; M32I-NEXT:    ld r4, [sp, 48]
; M32I-NEXT:    ld r14, [sp, 52]
; M32I-NEXT:    addi sp, sp, 56
; M32I-NEXT:    ret
  %1 = call i32 @callee_large_scalars_exhausted_regs(
      i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i128 8, i32 9,
      fp128 0xL00000000000000007FFF000000000000)
  ret i32 %1
}

; Ensure that libcalls generated in the middle-end obey the calling convention

define i32 @caller_mixed_scalar_libcalls(i64 %a) nounwind {
; M32I-LABEL: caller_mixed_scalar_libcalls:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r2, %hi(__floatditf)
; M32I-NEXT:    movl r2, %lo(__floatditf)
; M32I-NEXT:    rcall r2, 0
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = sitofp i64 %a to fp128
  %2 = bitcast fp128 %1 to i128
  %3 = trunc i128 %2 to i32
  ret i32 %3
}

; Check that the stack is used once the GPRs are exhausted

define i32 @callee_many_scalars(i8 %a, i16 %b, i32 %c, i64 %d, i32 %e, i32 %f, i64 %g, i32 %h) nounwind {
; M32I-LABEL: callee_many_scalars:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -12
; M32I-NEXT:    st r14, [sp, 8]
; M32I-NEXT:    st r4, [sp, 4]
; M32I-NEXT:    st r5, [sp, 0]
; M32I-NEXT:    addi r14, sp, 12
; M32I-NEXT:    ld r4, [r14, 16]
; M32I-NEXT:    xor r3, r3, r4
; M32I-NEXT:    addi r4, r14, 16
; M32I-NEXT:    ld r4, [r4, 4]
; M32I-NEXT:    ld r5, [r14, 4]
; M32I-NEXT:    xor r4, r5, r4
; M32I-NEXT:    or r3, r3, r4
; M32I-NEXT:    movu r4, 0
; M32I-NEXT:    movl r4, 65535
; M32I-NEXT:    and r1, r1, r4
; M32I-NEXT:    andi r0, r0, 255
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    add r0, r0, r2
; M32I-NEXT:    cmpi.eq r3, 0
; M32I-NEXT:    movi r1, 0
; M32I-NEXT:    mti r1, 1
; M32I-NEXT:    add r0, r1, r0
; M32I-NEXT:    ld r1, [r14, 8]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r1, [r14, 12]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r1, [r14, 24]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r5, [sp, 0]
; M32I-NEXT:    ld r4, [sp, 4]
; M32I-NEXT:    ld r14, [sp, 8]
; M32I-NEXT:    addi sp, sp, 12
; M32I-NEXT:    ret
  %a_ext = zext i8 %a to i32
  %b_ext = zext i16 %b to i32
  %1 = add i32 %a_ext, %b_ext
  %2 = add i32 %1, %c
  %3 = icmp eq i64 %d, %g
  %4 = zext i1 %3 to i32
  %5 = add i32 %4, %2
  %6 = add i32 %5, %e
  %7 = add i32 %6, %f
  %8 = add i32 %7, %h
  ret i32 %8
}

define i32 @caller_many_scalars() nounwind {
; M32I-LABEL: caller_many_scalars:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -32
; M32I-NEXT:    st r14, [sp, 28]
; M32I-NEXT:    st r4, [sp, 24]
; M32I-NEXT:    addi r14, sp, 32
; M32I-NEXT:    movi r0, 8
; M32I-NEXT:    st r0, [sp, 20]
; M32I-NEXT:    movi r0, 7
; M32I-NEXT:    st r0, [sp, 12]
; M32I-NEXT:    movi r0, 6
; M32I-NEXT:    st r0, [sp, 8]
; M32I-NEXT:    movi r0, 5
; M32I-NEXT:    st r0, [sp, 4]
; M32I-NEXT:    movi r0, 0
; M32I-NEXT:    st r0, [sp, 16]
; M32I-NEXT:    st r0, [sp, 0]
; M32I-NEXT:    movu r4, %hi(callee_many_scalars)
; M32I-NEXT:    movl r4, %lo(callee_many_scalars)
; M32I-NEXT:    movi r0, 1
; M32I-NEXT:    movi r1, 2
; M32I-NEXT:    movi r2, 3
; M32I-NEXT:    movi r3, 4
; M32I-NEXT:    rcall r4, 0
; M32I-NEXT:    ld r4, [sp, 24]
; M32I-NEXT:    ld r14, [sp, 28]
; M32I-NEXT:    addi sp, sp, 32
; M32I-NEXT:    ret
  %1 = call i32 @callee_many_scalars(i8 1, i16 2, i32 3, i64 4, i32 5, i32 6, i64 7, i32 8)
  ret i32 %1
}

; Check passing of coerced integer arrays

%struct.small = type { i32, i32* }

define i32 @callee_small_coerced_struct([2 x i32] %a.coerce) nounwind {
; M32I-LABEL: callee_small_coerced_struct:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    cmp.eq r0, r1
; M32I-NEXT:    movi r0, 0
; M32I-NEXT:    mti r0, 1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = extractvalue [2 x i32] %a.coerce, 0
  %2 = extractvalue [2 x i32] %a.coerce, 1
  %3 = icmp eq i32 %1, %2
  %4 = zext i1 %3 to i32
  ret i32 %4
}

define i32 @caller_small_coerced_struct() nounwind {
; M32I-LABEL: caller_small_coerced_struct:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r2, %hi(callee_small_coerced_struct)
; M32I-NEXT:    movl r2, %lo(callee_small_coerced_struct)
; M32I-NEXT:    movi r0, 1
; M32I-NEXT:    movi r1, 2
; M32I-NEXT:    rcall r2, 0
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = call i32 @callee_small_coerced_struct([2 x i32] [i32 1, i32 2])
  ret i32 %1
}

; Check large struct arguments, which are passed byval

%struct.large = type { i32, i32, i32, i32 }

define i32 @callee_large_struct(%struct.large* byval align 4 %a) nounwind {
; M32I-LABEL: callee_large_struct:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ld r1, [r0, 12]
; M32I-NEXT:    ld r0, [r0, 0]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = getelementptr inbounds %struct.large, %struct.large* %a, i32 0, i32 0
  %2 = getelementptr inbounds %struct.large, %struct.large* %a, i32 0, i32 3
  %3 = load i32, i32* %1
  %4 = load i32, i32* %2
  %5 = add i32 %3, %4
  ret i32 %5
}

define i32 @caller_large_struct() nounwind {
; M32I-LABEL: caller_large_struct:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -36
; M32I-NEXT:    st r14, [sp, 32]
; M32I-NEXT:    addi r14, sp, 36
; M32I-NEXT:    addi r0, r14, -20
; M32I-NEXT:    movi r1, 4
; M32I-NEXT:    st r1, [r0, 12]
; M32I-NEXT:    movi r2, 3
; M32I-NEXT:    st r2, [r0, 8]
; M32I-NEXT:    movi r3, 2
; M32I-NEXT:    st r3, [r0, 4]
; M32I-NEXT:    addi r0, r14, -36
; M32I-NEXT:    st r3, [r0, 4]
; M32I-NEXT:    st r2, [r0, 8]
; M32I-NEXT:    st r1, [r0, 12]
; M32I-NEXT:    movi r1, 1
; M32I-NEXT:    st r1, [r14, -20]
; M32I-NEXT:    st r1, [r14, -36]
; M32I-NEXT:    movu r1, %hi(callee_large_struct)
; M32I-NEXT:    movl r1, %lo(callee_large_struct)
; M32I-NEXT:    rcall r1, 0
; M32I-NEXT:    ld r14, [sp, 32]
; M32I-NEXT:    addi sp, sp, 36
; M32I-NEXT:    ret
  %ls = alloca %struct.large, align 4
  %1 = bitcast %struct.large* %ls to i8*
  %a = getelementptr inbounds %struct.large, %struct.large* %ls, i32 0, i32 0
  store i32 1, i32* %a
  %b = getelementptr inbounds %struct.large, %struct.large* %ls, i32 0, i32 1
  store i32 2, i32* %b
  %c = getelementptr inbounds %struct.large, %struct.large* %ls, i32 0, i32 2
  store i32 3, i32* %c
  %d = getelementptr inbounds %struct.large, %struct.large* %ls, i32 0, i32 3
  store i32 4, i32* %d
  %2 = call i32 @callee_large_struct(%struct.large* byval align 4 %ls)
  ret i32 %2
}

; Must keep define on a single line due to an update_llc_test_checks.py limitation
define i32 @callee_aligned_stack(i32 %a, i32 %b, fp128 %c, i32 %d, i32 %e, i64 %f, i32 %g, i32 %h, double %i, i32 %j, [2 x i32] %k) nounwind {
; M32I-LABEL: callee_aligned_stack:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ld r0, [r14, 28]
; M32I-NEXT:    add r0, r2, r0
; M32I-NEXT:    ld r1, [r14, 32]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r1, [r14, 36]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r1, [r14, 44]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r1, [r14, 48]
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = bitcast fp128 %c to i128
  %2 = trunc i128 %1 to i32
  %3 = add i32 %2, %g
  %4 = add i32 %3, %h
  %5 = bitcast double %i to i64
  %6 = trunc i64 %5 to i32
  %7 = add i32 %4, %6
  %8 = add i32 %7, %j
  %9 = extractvalue [2 x i32] %k, 0
  %10 = add i32 %8, %9
  ret i32 %10
}

define void @caller_aligned_stack() nounwind {
; M32I-LABEL: caller_aligned_stack:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -60
; M32I-NEXT:    st r14, [sp, 56]
; M32I-NEXT:    st r4, [sp, 52]
; M32I-NEXT:    addi r14, sp, 60
; M32I-NEXT:    movi r0, 18
; M32I-NEXT:    st r0, [sp, 48]
; M32I-NEXT:    movi r0, 17
; M32I-NEXT:    st r0, [sp, 44]
; M32I-NEXT:    movi r0, 16
; M32I-NEXT:    st r0, [sp, 40]
; M32I-NEXT:    movu r0, 16389
; M32I-NEXT:    movl r0, 49807
; M32I-NEXT:    st r0, [sp, 36]
; M32I-NEXT:    movu r0, 23592
; M32I-NEXT:    movl r0, 62915
; M32I-NEXT:    st r0, [sp, 32]
; M32I-NEXT:    movi r0, 15
; M32I-NEXT:    st r0, [sp, 28]
; M32I-NEXT:    movi r0, 14
; M32I-NEXT:    st r0, [sp, 24]
; M32I-NEXT:    movi r0, 4
; M32I-NEXT:    st r0, [sp, 20]
; M32I-NEXT:    movu r0, 43031
; M32I-NEXT:    movl r0, 51200
; M32I-NEXT:    st r0, [sp, 16]
; M32I-NEXT:    movi r0, 13
; M32I-NEXT:    st r0, [sp, 12]
; M32I-NEXT:    movi r0, 12
; M32I-NEXT:    st r0, [sp, 8]
; M32I-NEXT:    movu r0, 16384
; M32I-NEXT:    movl r0, 37355
; M32I-NEXT:    st r0, [sp, 4]
; M32I-NEXT:    movu r0, 34078
; M32I-NEXT:    movl r0, 47185
; M32I-NEXT:    st r0, [sp, 0]
; M32I-NEXT:    movu r2, 20971
; M32I-NEXT:    movl r2, 34079
; M32I-NEXT:    movu r3, 60293
; M32I-NEXT:    movl r3, 7864
; M32I-NEXT:    movu r4, %hi(callee_aligned_stack)
; M32I-NEXT:    movl r4, %lo(callee_aligned_stack)
; M32I-NEXT:    movi r0, 1
; M32I-NEXT:    movi r1, 11
; M32I-NEXT:    rcall r4, 0
; M32I-NEXT:    ld r4, [sp, 52]
; M32I-NEXT:    ld r14, [sp, 56]
; M32I-NEXT:    addi sp, sp, 60
; M32I-NEXT:    ret
  %1 = call i32 @callee_aligned_stack(i32 1, i32 11,
    fp128 0xLEB851EB851EB851F400091EB851EB851, i32 12, i32 13,
    i64 20000000000, i32 14, i32 15, double 2.720000e+00, i32 16,
    [2 x i32] [i32 17, i32 18])
  ret void
}

; Check return of 64 bit scalars

define i64 @callee_small_scalar_ret() nounwind {
; M32I-LABEL: callee_small_scalar_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r0, 29179
; M32I-NEXT:    movl r0, 9869
; M32I-NEXT:    movi r1, 287
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  ret i64 1234567898765
}

define i32 @caller_small_scalar_ret() nounwind {
; M32I-LABEL: caller_small_scalar_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r0, %hi(callee_small_scalar_ret)
; M32I-NEXT:    movl r0, %lo(callee_small_scalar_ret)
; M32I-NEXT:    rcall r0, 0
; M32I-NEXT:    movu r2, 3
; M32I-NEXT:    movl r2, 33348
; M32I-NEXT:    xor r1, r1, r2
; M32I-NEXT:    movu r2, 12538
; M32I-NEXT:    movl r2, 25223
; M32I-NEXT:    xor r0, r0, r2
; M32I-NEXT:    or r0, r0, r1
; M32I-NEXT:    cmpi.eq r0, 0
; M32I-NEXT:    movi r0, 0
; M32I-NEXT:    mti r0, 1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = call i64 @callee_small_scalar_ret()
  %2 = icmp eq i64 987654321234567, %1
  %3 = zext i1 %2 to i32
  ret i32 %3
}

; Check return of 64 bit structs

define %struct.small @callee_small_struct_ret() nounwind {
; M32I-LABEL: callee_small_struct_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movi r0, 1
; M32I-NEXT:    movi r1, 0
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  ret %struct.small { i32 1, i32* null }
}

define i32 @caller_small_struct_ret() nounwind {
; M32I-LABEL: caller_small_struct_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r0, %hi(callee_small_struct_ret)
; M32I-NEXT:    movl r0, %lo(callee_small_struct_ret)
; M32I-NEXT:    rcall r0, 0
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = call %struct.small @callee_small_struct_ret()
  %2 = extractvalue %struct.small %1, 0
  %3 = extractvalue %struct.small %1, 1
  %4 = ptrtoint i32* %3 to i32
  %5 = add i32 %2, %4
  ret i32 %5
}

; Check return of 128 bit scalars

define fp128 @callee_large_scalar_ret() nounwind {
; M32I-LABEL: callee_large_scalar_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movi r0, 0
; M32I-NEXT:    movu r3, 32767
; M32I-NEXT:    mov r1, r0
; M32I-NEXT:    mov r2, r0
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  ret fp128 0xL00000000000000007FFF000000000000
}

define void @caller_large_scalar_ret() nounwind {
; M32I-LABEL: caller_large_scalar_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r0, %hi(callee_large_scalar_ret)
; M32I-NEXT:    movl r0, %lo(callee_large_scalar_ret)
; M32I-NEXT:    rcall r0, 0
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = call fp128 @callee_large_scalar_ret()
  ret void
}

; Check return of 128 bit structs

define void @callee_large_struct_ret(%struct.large* noalias sret %agg.result) nounwind {
; M32I-LABEL: callee_large_struct_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movi r1, 4
; M32I-NEXT:    st r1, [r0, 12]
; M32I-NEXT:    movi r1, 3
; M32I-NEXT:    st r1, [r0, 8]
; M32I-NEXT:    movi r1, 2
; M32I-NEXT:    st r1, [r0, 4]
; M32I-NEXT:    movi r1, 1
; M32I-NEXT:    st r1, [r0, 0]
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %a = getelementptr inbounds %struct.large, %struct.large* %agg.result, i32 0, i32 0
  store i32 1, i32* %a, align 4
  %b = getelementptr inbounds %struct.large, %struct.large* %agg.result, i32 0, i32 1
  store i32 2, i32* %b, align 4
  %c = getelementptr inbounds %struct.large, %struct.large* %agg.result, i32 0, i32 2
  store i32 3, i32* %c, align 4
  %d = getelementptr inbounds %struct.large, %struct.large* %agg.result, i32 0, i32 3
  store i32 4, i32* %d, align 4
  ret void
}

define i32 @caller_large_struct_ret() nounwind {
; M32I-LABEL: caller_large_struct_ret:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -24
; M32I-NEXT:    st r14, [sp, 20]
; M32I-NEXT:    st r4, [sp, 16]
; M32I-NEXT:    addi r14, sp, 24
; M32I-NEXT:    movu r1, %hi(callee_large_struct_ret)
; M32I-NEXT:    movl r1, %lo(callee_large_struct_ret)
; M32I-NEXT:    addi r4, r14, -24
; M32I-NEXT:    mov r0, r4
; M32I-NEXT:    rcall r1, 0
; M32I-NEXT:    ld r0, [r4, 12]
; M32I-NEXT:    ld r1, [r14, -24]
; M32I-NEXT:    add r0, r1, r0
; M32I-NEXT:    addi sp, r14, -24
; M32I-NEXT:    ld r4, [sp, 16]
; M32I-NEXT:    ld r14, [sp, 20]
; M32I-NEXT:    addi sp, sp, 24
; M32I-NEXT:    ret
  %1 = alloca %struct.large
  call void @callee_large_struct_ret(%struct.large* sret %1)
  %2 = getelementptr inbounds %struct.large, %struct.large* %1, i32 0, i32 0
  %3 = load i32, i32* %2
  %4 = getelementptr inbounds %struct.large, %struct.large* %1, i32 0, i32 3
  %5 = load i32, i32* %4
  %6 = add i32 %3, %5
  ret i32 %6
}
