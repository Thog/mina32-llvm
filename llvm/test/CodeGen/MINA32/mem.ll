; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=mina32 -verify-machineinstrs < %s \
; RUN:   | FileCheck %s -check-prefix=M32I

; Check indexed and unindexed, sext, zext and anyext loads

define i32 @ldb(i8 *%a) nounwind {
; M32I-LABEL: ldb:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ldb r1, [r0, 0]
; M32I-NEXT:    ldb r0, [r0, 1]
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = getelementptr i8, i8* %a, i32 1
  %2 = load i8, i8* %1
  %3 = zext i8 %2 to i32
  ; the unused load will produce an anyext for selection
  %4 = load volatile i8, i8* %a
  ret i32 %3
}

define i32 @ldh(i16 *%a) nounwind {
; M32I-LABEL: ldh:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ldh r1, [r0, 0]
; M32I-NEXT:    ldh r0, [r0, 4]
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = getelementptr i16, i16* %a, i32 2
  %2 = load i16, i16* %1
  %3 = zext i16 %2 to i32
  ; the unused load will produce an anyext for selection
  %4 = load volatile i16, i16* %a
  ret i32 %3
}

define i32 @ld(i32 *%a) nounwind {
; M32I-LABEL: ld:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ld r1, [r0, 0]
; M32I-NEXT:    ld r0, [r0, 12]
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = getelementptr i32, i32* %a, i32 3
  %2 = load i32, i32* %1
  ; the unused load will produce an anyext for selection
  %3 = load volatile i32, i32* %a
  ret i32 %2
}

define i32 @ldb_sext(i8 *%a) nounwind {
; M32I-LABEL: ldb_sext:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ldb r1, [r0, 0]
; M32I-NEXT:    lsl r1, r1, 24
; M32I-NEXT:    asr r1, r1, 24
; M32I-NEXT:    ldb r0, [r0, 1]
; M32I-NEXT:    lsl r0, r0, 24
; M32I-NEXT:    asr r0, r0, 24
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = getelementptr i8, i8* %a, i32 1
  %2 = load i8, i8* %1
  %3 = sext i8 %2 to i32
  %4 = load volatile i8, i8* %a
  %5 = sext i8 %4 to i32
  %6 = add i32 %3, %5
  ret i32 %6
}

define i32 @ldh_sext(i16 *%a) nounwind {
; M32I-LABEL: ldh_sext:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ldh r1, [r0, 0]
; M32I-NEXT:    lsl r1, r1, 16
; M32I-NEXT:    asr r1, r1, 16
; M32I-NEXT:    ldh r0, [r0, 4]
; M32I-NEXT:    lsl r0, r0, 16
; M32I-NEXT:    asr r0, r0, 16
; M32I-NEXT:    add r0, r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = getelementptr i16, i16* %a, i32 2
  %2 = load i16, i16* %1
  %3 = sext i16 %2 to i32
  %4 = load volatile i16, i16* %a
  %5 = sext i16 %4 to i32
  %6 = add i32 %3, %5
  ret i32 %6
}

; Check indexed and unindexed stores

define void @stb(i8 *%a, i8 %b) nounwind {
; M32I-LABEL: stb:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    stb r1, [r0, 4]
; M32I-NEXT:    stb r1, [r0, 0]
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  store i8 %b, i8* %a
  %1 = getelementptr i8, i8* %a, i32 4
  store i8 %b, i8* %1
  ret void
}

define void @sth(i16 *%a, i16 %b) nounwind {
; M32I-LABEL: sth:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    sth r1, [r0, 10]
; M32I-NEXT:    sth r1, [r0, 0]
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  store i16 %b, i16* %a
  %1 = getelementptr i16, i16* %a, i32 5
  store i16 %b, i16* %1
  ret void
}

define void @st(i32 *%a, i32 %b) nounwind {
; M32I-LABEL: st:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    st r1, [r0, 24]
; M32I-NEXT:    st r1, [r0, 0]
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  store i32 %b, i32* %a
  %1 = getelementptr i32, i32* %a, i32 6
  store i32 %b, i32* %1
  ret void
}

; Check load and store to an i1 location
define i32 @load_sext_zext_anyext_i1(i1 *%a) nounwind {
; M32I-LABEL: load_sext_zext_anyext_i1:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ldb r1, [r0, 0]
; M32I-NEXT:    ldb r1, [r0, 1]
; M32I-NEXT:    ldb r0, [r0, 2]
; M32I-NEXT:    sub r0, r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  ; sextload i1
  %1 = getelementptr i1, i1* %a, i32 1
  %2 = load i1, i1* %1
  %3 = sext i1 %2 to i32
  ; zextload i1
  %4 = getelementptr i1, i1* %a, i32 2
  %5 = load i1, i1* %4
  %6 = zext i1 %5 to i32
  %7 = add i32 %3, %6
  ; extload i1 (anyext). Produced as the load is unused.
  %8 = load volatile i1, i1* %a
  ret i32 %7
}

define i16 @load_sext_zext_anyext_i1_i16(i1 *%a) nounwind {
; M32I-LABEL: load_sext_zext_anyext_i1_i16:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    ldb r1, [r0, 0]
; M32I-NEXT:    ldb r1, [r0, 1]
; M32I-NEXT:    ldb r0, [r0, 2]
; M32I-NEXT:    sub r0, r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  ; sextload i1
  %1 = getelementptr i1, i1* %a, i32 1
  %2 = load i1, i1* %1
  %3 = sext i1 %2 to i16
  ; zextload i1
  %4 = getelementptr i1, i1* %a, i32 2
  %5 = load i1, i1* %4
  %6 = zext i1 %5 to i16
  %7 = add i16 %3, %6
  ; extload i1 (anyext). Produced as the load is unused.
  %8 = load volatile i1, i1* %a
  ret i16 %7
}

define i32 @ld_st_constant(i32 %a) nounwind {
; TODO: the addi should be folded in to the ld/st
; M32I-LABEL: ld_st_constant:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r2, 57005
; M32I-NEXT:    movl r2, 48879
; M32I-NEXT:    ld r1, [r2, 0]
; M32I-NEXT:    st r0, [r2, 0]
; M32I-NEXT:    mov r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = inttoptr i32 3735928559 to i32*
  %2 = load volatile i32, i32* %1
  store i32 %a, i32* %1
  ret i32 %2
}

; Check load and store to a global
@G = global i32 0

define i32 @lw_sw_global(i32 %a) nounwind {
; TODO: the addi should be folded in to the lw/sw operations
; M32I-LABEL: lw_sw_global:
; M32I:       ; %bb.0:
; M32I-NEXT:    addi sp, sp, -4
; M32I-NEXT:    st r14, [sp, 0]
; M32I-NEXT:    addi r14, sp, 4
; M32I-NEXT:    movu r2, %hi(G)
; M32I-NEXT:    movl r2, %lo(G)
; M32I-NEXT:    ld r1, [r2, 0]
; M32I-NEXT:    st r0, [r2, 0]
; M32I-NEXT:    movu r2, %hi(G+36)
; M32I-NEXT:    movl r2, %lo(G+36)
; M32I-NEXT:    ld r3, [r2, 0]
; M32I-NEXT:    st r0, [r2, 0]
; M32I-NEXT:    mov r0, r1
; M32I-NEXT:    ld r14, [sp, 0]
; M32I-NEXT:    addi sp, sp, 4
; M32I-NEXT:    ret
  %1 = load volatile i32, i32* @G
  store i32 %a, i32* @G
  %2 = getelementptr i32, i32* @G, i32 9
  %3 = load volatile i32, i32* %2
  store i32 %a, i32* %2
  ret i32 %1
}
